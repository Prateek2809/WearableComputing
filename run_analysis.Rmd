run_analysis, markdown version
========================================================

This is th markdown version of the `run_analysis.R` script. It's here for 
convenience - it may be easier to look at this to get a feel for what's invovled
in this project than to read and run the script right away.

### Step 0: Read in the data 
Assume the data have been downloaded into the current folder. If not, see
`downloadData.R` on how to do this
```{r, cache=TRUE}
path <- file.path("./", "UCI HAR Dataset")
list.files(path, recursive = TRUE)

# use `data.table` library to read data (instead of `data frames`; it's faster)
library(data.table)

# read the subject files (`subject IDs`):
DT.subject.ID.Train <- fread(file.path(path, "train", "subject_train.txt"))
DT.subject.ID.Test <- fread(file.path(path, "test", "subject_test.txt"))

# the `activity labels` (6 of them; see README):
DT.label.Train <- fread(file.path(path, "train", "Y_train.txt"))
DT.label.Test <- fread(file.path(path, "test", "Y_test.txt"))

# `fread` may fail to read the larger files. Solution: read the text files
# into `data frame`s and convert them to `data table`s.
df <- read.table(file.path(path, "train", "X_train.txt")) #takes a minute
DT.train <- data.table(df)
df <- read.table(file.path(path, "test", "X_test.txt"))    #takes a minute
DT.test <- data.table(df)
```



### Step 1: Merge the training and the test sets to create one data set.
```{r, cache=TRUE}
# subject IDs:
DT.All.subject.IDs <- rbind(DT.subject.ID.Train, DT.subject.ID.Test)
setnames(DT.All.subject.IDs, "V1", "subject")  #10, 299 total subjects

# labels: 
DT.All.labels <- rbind(DT.label.Train, DT.label.Test)
setnames(DT.All.labels, "V1", "activity.label")

# the `train` and `test` dataset:
DT.Train.and.Test <- rbind(DT.train , DT.test)


# Finally, merge the colums:
DT.All <- cbind(DT.All.subject.IDs, DT.Train.and.Test)
DT.All <- cbind(DT.All, DT.All.labels)

################### good! this is the merged dataset we want ###################
```
We have `10,299` observations and `563` variables in the meged dataset. The 
first variable in `DT.All` is `subject` (ID) and the last variable is the 
`activity.label` (a number 1-6 that represents an activity). 
```{r}
dim(DT.All)
```

### Step 2. Extract only the measurements on the mean and standard deviation for each measurement.

The `features.txt` file lists the names of all features. From these names 
we will extract the ones that contain `mean` and `std`. We have 66 features that
have either `mean` or `std` in their names. 

```{r,cache=TRUE}
DT.features <- fread(file.path(path, "features.txt"))
setnames(DT.features, names(DT.features), c("feature.number", "feature.name"))
DT.features <- DT.features[grepl("mean\\(\\)|std\\(\\)", feature.name)]
dim(DT.features)   # 66 by 2 
```
Now, here's an important step: with each of these features we associate a 
`feature.code` that matches the column name in the `DT.All` data table:

```{r,cache=TRUE}
DT.features$feature.code <- DT.features[, paste0("V", feature.number)]
tail(DT.features)

# DT.features$feature.code

##### Set `subject` and `activity.label` as keys:
setkey(DT.All, subject, activity.label)
##### And append the `feature.code` to this. These are the columns that we want
#     to extract from the `data.table`:
the.columns.we.want <- c(key(DT.All), DT.features$feature.code)
result <- DT.All[, the.columns.we.want, with=FALSE]
str(result)

```

### Step 3. Uses descriptive activity names to name the activities in the data set
So far, our activity labels were some not-very-informative-to-the-unitiated 
integers. We now set the more natural names for these labels. 
`activity_labels.txt` contains such 'natural' names: 

```{r,cache=TRUE}
DT.activity.names <- fread(file.path(path, "activity_labels.txt"))
setnames(DT.activity.names, names(DT.activity.names), c("activity.label", "activity.name"))
DT.activity.names
```

### Step 4: Appropriately label the data set with descriptive activity names
Now we can merge the `DT.activity.names`  with the `DT.All` 
`data.table` by `activity.label`. We use `reshape2` library to melt the dataset.
Here is what the result looks like:

```{r,cache=TRUE}
DT <- merge(result, DT.activity.names, by = "activity.label", all.x = TRUE)
#str(DT)
library(reshape2)
setkey(DT, subject, activity.label, activity.name)
DT <- data.table(melt(DT, key(DT), variable.name = "feature.code"))

DT <- merge(DT, DT.features[, list(feature.number, feature.code, feature.name)], by = "feature.code", 
            all.x = TRUE)

head(DT, n=10); tail(DT, n=10)
```

### Step 5: Create a second, independent tidy data set with the average of each variable for each activity and each subject.

We will be looking at features and selecting observations based on
- wheather the feature comes from the *frequency* or the *time* domain
- wheather it comes from the *Accelerometer* or the *Gyroscope* (which instrument)
- wheather the acceleration is due to *Gravity* or *Body*
- wheather the feature variable has *"mean"* or *"std"* in its name
- wheather the feature variable has *"Jerk"* or *"Mag"* (magnitude) in its name
- wheather it is an *-X*, *-Y*, or *-Z* spatial measurement



